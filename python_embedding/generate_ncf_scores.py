# ä¿å­˜ä¸º generate_ncf_scores.py
import pandas as pd
import numpy as np
import os
import tensorflow as tf
from sklearn.preprocessing import LabelEncoder

# ---------------------- æ ¸å¿ƒé…ç½®ï¼ˆä»…éœ€ç¡®è®¤è¿™1ä¸ªè·¯å¾„ï¼‰ ----------------------
# ä½ çš„é¡¹ç›®æ ¹ç›®å½•ï¼ˆpython_embeddingçš„ä¸Šçº§ç›®å½•ï¼‰
PROJECT_ROOT = "D:/xksj/final project/code/SparrowRecSys-master/SparrowRecSys-master"
# -----------------------------------------------------------------------

# è‡ªåŠ¨æ¨å¯¼æ‰€æœ‰æ–‡ä»¶è·¯å¾„ï¼ˆæ— éœ€æ‰‹åŠ¨æ”¹ï¼‰
MODEL_PATH = os.path.join(PROJECT_ROOT, "src/main/resources/webroot/modeldata/ncf_model.h5")
USER_MAPPING_PATH = os.path.join(PROJECT_ROOT, "src/main/resources/webroot/modeldata/user_mapping.npy")
ITEM_MAPPING_PATH = os.path.join(PROJECT_ROOT, "src/main/resources/webroot/modeldata/item_mapping.npy")
RATINGS_PATH = os.path.join(PROJECT_ROOT, "python_embedding/ml-25m/ratings.csv")  # å‡è®¾ratingsåœ¨python_embeddingä¸‹
OUTPUT_PATH = os.path.join(PROJECT_ROOT, "src/main/resources/webroot/modeldata/ncf_predict_scores.csv")

# ===================== è·¯å¾„æ£€æŸ¥ï¼ˆå…³é”®ï¼šé¿å…æ–‡ä»¶æ‰¾ä¸åˆ°ï¼‰ =====================
def check_file_exists(file_path, file_desc):
    if not os.path.exists(file_path):
        print(f"âŒ æ‰¾ä¸åˆ°{file_desc}ï¼Œè·¯å¾„ï¼š{file_path}")
        print("è¯·ç¡®è®¤æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œæˆ–ä¿®æ”¹PROJECT_ROOTè·¯å¾„ï¼")
        exit(1)
    print(f"âœ… æ‰¾åˆ°{file_desc}ï¼š{file_path}")

# æ£€æŸ¥å¿…è¦æ–‡ä»¶
check_file_exists(MODEL_PATH, "NCFæ¨¡å‹æ–‡ä»¶(ncf_model.h5)")
check_file_exists(USER_MAPPING_PATH, "ç”¨æˆ·æ˜ å°„æ–‡ä»¶(user_mapping.npy)")
check_file_exists(ITEM_MAPPING_PATH, "ç‰©å“æ˜ å°„æ–‡ä»¶(item_mapping.npy)")
check_file_exists(RATINGS_PATH, "è¯„åˆ†æ•°æ®æ–‡ä»¶(ratings.csv)")

# ===================== åŠ è½½æ¨¡å‹å’Œæ•°æ® =====================
print("\nåŠ è½½NCFæ¨¡å‹å’Œæ˜ å°„å…³ç³»...")
model = tf.keras.models.load_model(MODEL_PATH)
user_mapping = np.load(USER_MAPPING_PATH, allow_pickle=True).item()
item_mapping = np.load(ITEM_MAPPING_PATH, allow_pickle=True).item()

# æ„å»ºç¼–ç å™¨
user_encoder = LabelEncoder()
user_encoder.classes_ = np.array(list(user_mapping.keys()))
item_encoder = LabelEncoder()
item_encoder.classes_ = np.array(list(item_mapping.keys()))

# åŠ è½½è¯„åˆ†æ•°æ®ï¼ˆä»…ç”¨äºè¿‡æ»¤å·²äº¤äº’ç‰©å“ï¼‰
print("\nåŠ è½½è¯„åˆ†æ•°æ®...")
ratings = pd.read_csv(RATINGS_PATH)
user_counts = ratings['userId'].value_counts()
movie_counts = ratings['movieId'].value_counts()
active_users = user_counts[user_counts >= 20].index
popular_movies = movie_counts[movie_counts >= 50].index
filtered_ratings = ratings[
    (ratings['userId'].isin(active_users)) &
    (ratings['movieId'].isin(popular_movies))
].copy()
user_interacted_items = filtered_ratings.groupby('userId')['movieId'].apply(set).to_dict()

# ===================== ç”Ÿæˆé¢„æµ‹å¾—åˆ†ï¼ˆå¿«é€Ÿé‡‡æ ·ï¼Œé¿å…è€—æ—¶ï¼‰ =====================
print("\nç”ŸæˆNCFé¢„æµ‹å¾—åˆ†ï¼ˆé‡‡æ ·10%ç”¨æˆ·ï¼Œçº¦1åˆ†é’Ÿå®Œæˆï¼‰...")
predict_scores = []
# é‡‡æ ·10%ç”¨æˆ·ï¼ˆæµ‹è¯•ç”¨ï¼Œå…¨é‡å¯æ”¹0.5æˆ–1.0ï¼‰
sampled_users = np.random.choice(user_encoder.classes_, size=int(len(user_encoder.classes_)*0.1), replace=False)

for i, user_id in enumerate(sampled_users):
    if i % 100 == 0:
        print(f"è¿›åº¦ï¼š{i}/{len(sampled_users)} ç”¨æˆ·")
    
    # è½¬æ¢ç”¨æˆ·IDä¸ºæ¨¡å‹è¾“å…¥ç´¢å¼•
    try:
        user_idx = user_encoder.transform([user_id])[0]
    except:
        continue
    
    # å€™é€‰ç‰©å“ï¼šæ’é™¤å·²äº¤äº’çš„ï¼Œå–å‰500ä¸ªï¼ˆå‡å°‘è®¡ç®—é‡ï¼‰
    interacted = user_interacted_items.get(user_id, set())
    candidate_items = [item_id for item_id in item_encoder.classes_ if item_id not in interacted][:500]
    if not candidate_items:
        continue
    
    # æ‰¹é‡é¢„æµ‹å¾—åˆ†
    item_indices = item_encoder.transform(candidate_items)
    user_indices = np.full_like(item_indices, user_idx)
    scores = model.predict([user_indices, item_indices], batch_size=5000, verbose=0)
    
    # ä¿å­˜å¾—åˆ†ï¼ˆæ ¼å¼ï¼šuserID_itemID:scoreï¼‰
    for item_id, score in zip(candidate_items, scores):
        predict_scores.append(f"{user_id}_{item_id}:{float(score[0])}")

# ===================== ä¿å­˜æ–‡ä»¶ =====================
os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)
with open(OUTPUT_PATH, 'w', encoding='utf-8') as f:
    f.write('\n'.join(predict_scores))

print(f"\nğŸ‰ ç”Ÿæˆå®Œæˆï¼")
print(f"ğŸ“„ æ–‡ä»¶è·¯å¾„ï¼š{OUTPUT_PATH}")
print(f"ğŸ“Š å…±ç”Ÿæˆ {len(predict_scores)} æ¡ç”¨æˆ·-ç‰©å“é¢„æµ‹å¾—åˆ†")